{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nimport keras\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Embedding, GRU, Dense\nfrom keras.optimizers import Adam",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n  from ._conv import register_converters as _register_converters\nUsing TensorFlow backend.\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d40b9b9589e0d25ab17897319068246cc4f3e2ea",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train_data = pd.read_csv(\"../input/train.tsv\",sep='\\t')\ntest_data = pd.read_csv(\"../input/test.tsv\",sep='\\t')",
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "_kg_hide-input": false
      },
      "cell_type": "code",
      "source": "train_data.head()",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "   PhraseId  SentenceId                                             Phrase  \\\n0         1           1  A series of escapades demonstrating the adage ...   \n1         2           1  A series of escapades demonstrating the adage ...   \n2         3           1                                           A series   \n3         4           1                                                  A   \n4         5           1                                             series   \n\n   Sentiment  \n0          1  \n1          2  \n2          2  \n3          2  \n4          2  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PhraseId</th>\n      <th>SentenceId</th>\n      <th>Phrase</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>A series of escapades demonstrating the adage ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>A series of escapades demonstrating the adage ...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>A series</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>A</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>1</td>\n      <td>series</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e31694f0dc671ec0acc01546dc3f2c3d9f899876"
      },
      "cell_type": "code",
      "source": "y_train = pd.DataFrame(train_data['Sentiment'])\ny_train.loc[y_train['Sentiment'] < 2, 'Sentiment'] = 0\ny_train.loc[y_train['Sentiment'] >= 2, 'Sentiment'] = 1\ny_train = y_train.values\ny_train",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 21,
          "data": {
            "text/plain": "array([[0],\n       [1],\n       [1],\n       ...,\n       [1],\n       [1],\n       [1]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f4dc25d6d14f06bbfb2b2adc233646ad4b573198",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "inital = train_data['Phrase'].values\ninital = \" \".join(inital)\nallWords = np.array(inital.split(\" \"))\ninital = None\n# Create the Dictonary\ndef create_dict(words):\n    my_dict = {}\n    index = 1\n    for x in range(len(words) - 1):\n            try:\n                if(my_dict[words[x]]):\n                    pass\n            except:\n                my_dict[words[x]] = index\n                index += 1\n            finally:\n                pass\n    return my_dict\n\nwordsDict = create_dict(allWords)",
      "execution_count": 22,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "794b165396d5f6345b8a1361e9f78a0d1f93926d",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Tokenizer\ndef tokenize(string,token_dictonary):\n    tokenized_words = []\n    arrayOfWords = string.split(\" \")\n    for x in range(len(arrayOfWords)):\n        tokenized_words.append(token_dictonary[arrayOfWords[x]])\n    return np.array(tokenized_words)",
      "execution_count": 23,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5e7a5fb9ef18282189088d1ecbe23f4498715b64",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#tokenize(train_data['Phrase'][0],token_dictonary=wordsDict)\nx_train_tokens = []\nfor x in range(len(train_data['Phrase'])):\n    x_train_tokens.append(tokenize(train_data['Phrase'][x],wordsDict))",
      "execution_count": 24,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9ef0bb592922764761f3de3135ed11945d9dd21f"
      },
      "cell_type": "code",
      "source": "num_tokens = [len(token) for token in x_train_tokens+x_train_tokens]\nnum_tokens = np.array(num_tokens)\nnp.min(num_tokens)\nprint(len(wordsDict))",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": "18227\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6a0e7bd23b5d96ecda5bbec29b5a56afabc8d3be"
      },
      "cell_type": "code",
      "source": "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\nmax_tokens = int(max_tokens)\nmax_tokens",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 26,
          "data": {
            "text/plain": "21"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b4dadb5c2b696619e3042fcd795affc2b95a4873"
      },
      "cell_type": "code",
      "source": "np.sum(num_tokens<max_tokens)/len(num_tokens)",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 27,
          "data": {
            "text/plain": "0.9353069332308087"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "1d934896b9aaa0035f0a08ccb0344f9bb2f65f6b"
      },
      "cell_type": "code",
      "source": "x_train_pad = pad_sequences(x_train_tokens,maxlen=max_tokens,padding='pre',truncating='pre')",
      "execution_count": 28,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "be53d72cbc3d906812a6395e5875ec0acbc63676",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Model\nmodel = Sequential()\nembedding_size = 20\nmodel.add(Embedding(input_dim=len(wordsDict),output_dim=embedding_size,input_length=max_tokens))\nmodel.add(GRU(units=16,return_sequences=True))\nmodel.add(GRU(units=8,return_sequences=True))\nmodel.add(GRU(units=4))\nmodel.add(Dense(1,activation='sigmoid'))",
      "execution_count": 34,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "0680fa5aae3254d8ec3f4c447ba90e9abcbfb9ec"
      },
      "cell_type": "code",
      "source": "model.compile(loss=keras.losses.binary_crossentropy,optimizer=Adam(lr=1e-3),metrics=['accuracy'])",
      "execution_count": 35,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7df0012f9d92ed97c7a5e345599a414882a3097c"
      },
      "cell_type": "code",
      "source": "model.fit(x_train_pad,y_train,validation_split=0.05,epochs=3,batch_size=64)",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Train on 148257 samples, validate on 7803 samples\nEpoch 1/1\n148257/148257 [==============================] - 16s 107us/step - loss: 0.2268 - acc: 0.9054 - val_loss: 0.4767 - val_acc: 0.7969\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 38,
          "data": {
            "text/plain": "<keras.callbacks.History at 0x7fc3b1701d30>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "06cc6ad3ec058aeffc1084ff262cbc5f3eea5fbe"
      },
      "cell_type": "code",
      "source": "pre = [\"This is good\",\"This is bad\",\"This is fine\",\"This is stupid\"] \nallWords1tokenized = []\nfor x in range(len(pre)):\n    allWords1tokenized.append(tokenize(pre[x],wordsDict))\n\nallWords1tokenized_pad = pad_sequences(allWords1tokenized,maxlen=max_tokens,padding='pre',truncating='pre')\nallWords1tokenized_pad\nprediction = model.predict(allWords1tokenized_pad)\nfor x in range(len(pre)):\n    print(\"Statement: \" + pre[x])\n    print('Positive' if prediction[x] > 0.5 else 'Negative')\n    print()",
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Statement: This is good\nPositive\n\nStatement: This is bad\nNegative\n\nStatement: This is fine\nPositive\n\nStatement: This is stupid\nNegative\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "dc33869cdc7ea75eeb7a6b795cb1ab00a9a0a736"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}